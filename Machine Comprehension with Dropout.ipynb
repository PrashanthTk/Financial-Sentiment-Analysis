{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prashanththekkada/.virtualenvs/dl4cv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Dropout, Dense, Activation\n",
    "from keras.layers import LSTM, Bidirectional, Merge, Input\n",
    "from keras.layers import concatenate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "with h5py.File('context.h5', 'r') as hf:\n",
    "    context_array = hf['context'][:]\n",
    "with h5py.File('questions.h5', 'r') as hf:\n",
    "    question_array = hf['questions'][:]\n",
    "with h5py.File('begin.h5', 'r') as hf:\n",
    "    begin_span = hf['begin'][:]\n",
    "with h5py.File('end.h5', 'r') as hf:\n",
    "    end_span = hf['end'][:]\n",
    "    \n",
    "# loading Glove embeddings\n",
    "with h5py.File('embeddings_50.h5', 'r') as hf:\n",
    "    embedding_matrix = hf['embed'][:]\n",
    "    \n",
    "# loding vocabulary\n",
    "word_index = np.load('word_to_indx.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87598, 700)\n",
      "(87598, 50)\n",
      "(87598,)\n",
      "(87598,)\n"
     ]
    }
   ],
   "source": [
    "print (context_array.shape)\n",
    "print (question_array.shape)\n",
    "print (begin_span.shape)\n",
    "print (end_span.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print((context_array[0]==context_array[1]))\n",
    "#print((question_array[0]==question_array[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_index) + 1\n",
    "embedding_vector_length = 50\n",
    "max_span_begin = np.amax(begin_span)\n",
    "max_span_end = np.amax(end_span)\n",
    "batch = 8\n",
    "# slice of data to be used as one epoch training on full data is expensive\n",
    "slce = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1\n",
    "context_input = Input(shape=(700, ), dtype='int32', name='context_input')\n",
    "x = Embedding(input_dim=vocab_size, output_dim=50, weights=[embedding_matrix], \n",
    "              input_length=700, trainable=False)(context_input)\n",
    "lstm_out = Bidirectional(LSTM(256, return_sequences=True, implementation=2), merge_mode='concat')(x)\n",
    "drop_1 = Dropout(0.5)(lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2\n",
    "ques_input = Input(shape=(50, ), dtype='int32', name='ques_input')\n",
    "x = Embedding(input_dim=vocab_size, output_dim=50, weights=[embedding_matrix], \n",
    "              input_length=50, trainable=False)(ques_input)\n",
    "lstm_out = Bidirectional(LSTM(256, return_sequences=True, implementation=2), merge_mode='concat')(x)\n",
    "drop_2 = Dropout(0.5)(lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "context_input (InputLayer)      (None, 700)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ques_input (InputLayer)         (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 700, 50)      5984650     context_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 50, 50)       5984650     ques_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 700, 512)     628736      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 50, 512)      628736      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 700, 512)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50, 512)      0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 750, 512)     0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 512)          4198400     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3126)         1603638     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3136)         1608768     dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,637,578\n",
      "Trainable params: 8,668,278\n",
      "Non-trainable params: 11,969,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# merger model\n",
    "merge_layer = concatenate([drop_1, drop_2], axis=1)\n",
    "biLSTM = Bidirectional(LSTM(512, implementation=2), merge_mode='mul')(merge_layer)\n",
    "drop_3 =  Dropout(0.5)(biLSTM)\n",
    "softmax_1 = Dense(max_span_begin, activation='softmax')(drop_3)\n",
    "softmax_2 = Dense(max_span_end, activation='softmax')(drop_3)\n",
    "\n",
    "model = Model(inputs=[context_input, ques_input], outputs=[softmax_1, softmax_2])\n",
    "adam01=optimizers.Adam(lr=0.1)\n",
    "adam001=optimizers.Adam(lr=0.01)\n",
    "adam=optimizers.Adam(lr=0.001)\n",
    "#model.compile(optimizer=fast, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''slce=1\n",
    "model_history = model.fit([context_array[:slce], question_array[:slce]],\n",
    "                        [begin_span[:slce], end_span[:slce]], verbose=2,\n",
    "                         batch_size=batch, epochs=1)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 318s - loss: 29.2064 - dense_3_loss: 14.6762 - dense_4_loss: 14.5302 - dense_3_acc: 0.0040 - dense_4_acc: 0.0030\n"
     ]
    }
   ],
   "source": [
    "'''import keras\n",
    "model=keras.models.load_model('modelstep30')\n",
    "model.load_weights('./modelweights/QANet2_weights.h5')'''\n",
    "stindex=0\n",
    "endindex=1000\n",
    "model.compile(optimizer=adam01, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit([context_array[stindex:endindex], question_array[stindex:endindex]],\n",
    "                [begin_span[stindex:endindex], end_span[stindex:endindex]], verbose=2,\n",
    "                 batch_size=64, epochs=1,shuffle=True)\n",
    "model.save_weights('./dropout/adam01epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 314s - loss: 31.9144 - dense_3_loss: 16.0539 - dense_4_loss: 15.8605 - dense_3_acc: 0.0040 - dense_4_acc: 0.0050\n",
      "Epoch 2/5\n",
      " - 311s - loss: 31.8629 - dense_3_loss: 16.0539 - dense_4_loss: 15.8090 - dense_3_acc: 0.0040 - dense_4_acc: 0.0070\n",
      "Epoch 3/5\n",
      " - 310s - loss: 31.8258 - dense_3_loss: 16.0360 - dense_4_loss: 15.7898 - dense_3_acc: 0.0040 - dense_4_acc: 0.0050\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-83988e0129b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m history = model.fit([context_array[stindex:endindex], question_array[stindex:endindex]],\n\u001b[1;32m      5\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mbegin_span\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mendindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_span\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mendindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                  batch_size=64, epochs=5,shuffle=True)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dropout/adam001_5epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_weights('./dropout/adam01epoch')\n",
    "model.compile(optimizer=adam001, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit([context_array[stindex:endindex], question_array[stindex:endindex]],\n",
    "                [begin_span[stindex:endindex], end_span[stindex:endindex]], verbose=2,\n",
    "                 batch_size=64, epochs=5,shuffle=True)\n",
    "model.save_weights('./dropout/adam001_5epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " - 311s - loss: 9.7595 - dense_3_loss: 4.8560 - dense_4_loss: 4.9035 - dense_3_acc: 0.0590 - dense_4_acc: 0.0570\n",
      "Epoch 2/25\n",
      " - 312s - loss: 9.7302 - dense_3_loss: 4.8421 - dense_4_loss: 4.8881 - dense_3_acc: 0.0550 - dense_4_acc: 0.0570\n",
      "Epoch 3/25\n",
      " - 311s - loss: 9.6968 - dense_3_loss: 4.8254 - dense_4_loss: 4.8714 - dense_3_acc: 0.0590 - dense_4_acc: 0.0580\n",
      "Epoch 4/25\n",
      " - 311s - loss: 9.6573 - dense_3_loss: 4.8054 - dense_4_loss: 4.8519 - dense_3_acc: 0.0610 - dense_4_acc: 0.0550\n",
      "Epoch 5/25\n",
      " - 312s - loss: 9.6250 - dense_3_loss: 4.7894 - dense_4_loss: 4.8355 - dense_3_acc: 0.0620 - dense_4_acc: 0.0590\n",
      "Epoch 6/25\n",
      " - 311s - loss: 9.5909 - dense_3_loss: 4.7729 - dense_4_loss: 4.8180 - dense_3_acc: 0.0620 - dense_4_acc: 0.0590\n",
      "Epoch 7/25\n",
      " - 312s - loss: 9.5568 - dense_3_loss: 4.7561 - dense_4_loss: 4.8007 - dense_3_acc: 0.0630 - dense_4_acc: 0.0600\n",
      "Epoch 8/25\n",
      " - 311s - loss: 9.5248 - dense_3_loss: 4.7413 - dense_4_loss: 4.7835 - dense_3_acc: 0.0640 - dense_4_acc: 0.0590\n",
      "Epoch 9/25\n",
      " - 311s - loss: 9.5023 - dense_3_loss: 4.7290 - dense_4_loss: 4.7733 - dense_3_acc: 0.0640 - dense_4_acc: 0.0600\n",
      "Epoch 10/25\n",
      " - 312s - loss: 9.4735 - dense_3_loss: 4.7153 - dense_4_loss: 4.7583 - dense_3_acc: 0.0640 - dense_4_acc: 0.0570\n",
      "Epoch 11/25\n",
      " - 311s - loss: 9.4341 - dense_3_loss: 4.6954 - dense_4_loss: 4.7387 - dense_3_acc: 0.0650 - dense_4_acc: 0.0590\n",
      "Epoch 12/25\n",
      " - 310s - loss: 9.4063 - dense_3_loss: 4.6813 - dense_4_loss: 4.7249 - dense_3_acc: 0.0670 - dense_4_acc: 0.0610\n",
      "Epoch 13/25\n",
      " - 312s - loss: 9.3795 - dense_3_loss: 4.6673 - dense_4_loss: 4.7122 - dense_3_acc: 0.0670 - dense_4_acc: 0.0610\n",
      "Epoch 14/25\n",
      " - 308s - loss: 9.3538 - dense_3_loss: 4.6570 - dense_4_loss: 4.6968 - dense_3_acc: 0.0680 - dense_4_acc: 0.0590\n",
      "Epoch 15/25\n",
      " - 311s - loss: 9.3700 - dense_3_loss: 4.6649 - dense_4_loss: 4.7050 - dense_3_acc: 0.0610 - dense_4_acc: 0.0590\n",
      "Epoch 16/25\n",
      " - 312s - loss: 9.4051 - dense_3_loss: 4.6827 - dense_4_loss: 4.7224 - dense_3_acc: 0.0630 - dense_4_acc: 0.0610\n",
      "Epoch 17/25\n"
     ]
    }
   ],
   "source": [
    "#def triphase_modelfitter(model,optimizerlist,context_array,question_array,begin_span,end_span,batches,epochlist,slces):\n",
    "#First we fit the model with a learning rate of 0.1 for 5 epochs and 10 questions,batch_size=32\n",
    "#Next round, we fit with lr=0.01, 5 epochs and 100 qs,batch_size=16,\n",
    "#Last round we fit with lr=0.001, 5 epochs and 1000 qs, batch_size=8\n",
    "#This model has no dropout in the last layer.\n",
    "optimizerlist=[adam,adam,adam]\n",
    "slces=[[0,1000],[0,1000],[1000,2000],[4500,5000]]#train first round with qs from 0 to 1000 \n",
    "epochlist=[10,10,10,10]\n",
    "batches=[64,64,16,16]\n",
    "#triphase_modelfitter(model,optimizerlist,context_array,question_array,begin_span,end_span,batches,epochlist,slces)\n",
    "for step in range(1):\n",
    "    #model.compile(optimizer=optimizerlist[step], loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    stindex=0\n",
    "    endindex=1000\n",
    "\n",
    "    history = model.fit([context_array[stindex:endindex], question_array[stindex:endindex]],\n",
    "                    [begin_span[stindex:endindex], end_span[stindex:endindex]], verbose=2,\n",
    "                     batch_size=64, epochs=25,shuffle=True)\n",
    "    \"\"\"model_history = model.fit([context_array[:slces[step]], question_array[:slces[step]]],\n",
    "                    [begin_span[:slces[step]], end_span[:slces[step]]], verbose=2,\n",
    "                     batch_size=batches[step], epochs=epochlist[step])\"\"\"\n",
    "\n",
    "    history\n",
    "    '''plt.plot(history.history['dense_9_acc'])\n",
    "    #plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy step:'+str(step))\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()'''\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    #plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss step:'+str(step))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    modelname='model95epochs'+str(step)\n",
    "    model.save(modelname)\n",
    "    model.save_weights('./modelweights/QANet95epochs'+str(step)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./modelweights/QANet2_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history=model_history\n",
    "plt.plot(history.history['dense_4_acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'dense_3_loss', 'dense_4_loss', 'dense_3_acc', 'dense_4_acc'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "context_input (InputLayer)      (None, 700)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ques_input (InputLayer)         (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 700, 50)      5984650     context_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 50, 50)       5984650     ques_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 700, 512)     628736      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 50, 512)      628736      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 700, 512)     0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 50, 512)      0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 750, 512)     0           dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 512)          4198400     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 3126)         1603638     bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3136)         1608768     bidirectional_9[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 20,637,578\n",
      "Trainable params: 8,668,278\n",
      "Non-trainable params: 11,969,300\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 320s - loss: 15.9292 - dense_5_loss: 7.9613 - dense_6_loss: 7.9679 - dense_5_acc: 0.0180 - dense_6_acc: 0.0030\n",
      "Epoch 2/10\n",
      " - 318s - loss: 13.8707 - dense_5_loss: 6.9303 - dense_6_loss: 6.9404 - dense_5_acc: 0.0140 - dense_6_acc: 0.0070\n",
      "Epoch 3/10\n",
      " - 316s - loss: 12.6127 - dense_5_loss: 6.3066 - dense_6_loss: 6.3061 - dense_5_acc: 0.0150 - dense_6_acc: 0.0080\n",
      "Epoch 4/10\n",
      " - 313s - loss: 12.3726 - dense_5_loss: 6.1733 - dense_6_loss: 6.1993 - dense_5_acc: 0.0230 - dense_6_acc: 0.0090\n",
      "Epoch 5/10\n",
      " - 314s - loss: 12.3005 - dense_5_loss: 6.1406 - dense_6_loss: 6.1599 - dense_5_acc: 0.0230 - dense_6_acc: 0.0110\n",
      "Epoch 6/10\n",
      " - 313s - loss: 12.2963 - dense_5_loss: 6.1402 - dense_6_loss: 6.1561 - dense_5_acc: 0.0230 - dense_6_acc: 0.0090\n",
      "Epoch 7/10\n",
      " - 314s - loss: 12.2843 - dense_5_loss: 6.1351 - dense_6_loss: 6.1492 - dense_5_acc: 0.0230 - dense_6_acc: 0.0090\n",
      "Epoch 8/10\n",
      " - 314s - loss: 12.2792 - dense_5_loss: 6.1290 - dense_6_loss: 6.1502 - dense_5_acc: 0.0230 - dense_6_acc: 0.0110\n",
      "Epoch 9/10\n",
      " - 313s - loss: 12.2696 - dense_5_loss: 6.1262 - dense_6_loss: 6.1433 - dense_5_acc: 0.0230 - dense_6_acc: 0.0050\n",
      "Epoch 10/10\n",
      " - 315s - loss: 12.2645 - dense_5_loss: 6.1233 - dense_6_loss: 6.1412 - dense_5_acc: 0.0230 - dense_6_acc: 0.0080\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_index) + 1\n",
    "embedding_vector_length = 50\n",
    "max_span_begin = np.amax(begin_span)\n",
    "max_span_end = np.amax(end_span)\n",
    "batch = 64\n",
    "# slice of data to be used as one epoch training on full data is expensive\n",
    "slce = 1000\n",
    "\n",
    "# model1\n",
    "context_input = Input(shape=(700, ), dtype='int32', name='context_input')\n",
    "x = Embedding(input_dim=vocab_size, output_dim=50, weights=[embedding_matrix],\n",
    "              input_length=700, trainable=False)(context_input)\n",
    "lstm_out = Bidirectional(LSTM(256, return_sequences=True, implementation=2), merge_mode='concat')(x)\n",
    "drop_1 = Dropout(0.5)(lstm_out)\n",
    "\n",
    "# model2\n",
    "ques_input = Input(shape=(50, ), dtype='int32', name='ques_input')\n",
    "x = Embedding(input_dim=vocab_size, output_dim=50, weights=[embedding_matrix],\n",
    "              input_length=50, trainable=False)(ques_input)\n",
    "lstm_out = Bidirectional(LSTM(256, return_sequences=True, implementation=2), merge_mode='concat')(x)\n",
    "drop_2 = Dropout(0.5)(lstm_out)\n",
    "\n",
    "# merger model\n",
    "merge_layer = concatenate([drop_1, drop_2], axis=1)\n",
    "biLSTM = Bidirectional(LSTM(512, implementation=2), merge_mode='mul')(merge_layer)\n",
    "drop_3 =  Dropout(0.5)(biLSTM)\n",
    "softmax_1 = Dense(max_span_begin, activation='softmax')(biLSTM)\n",
    "softmax_2 = Dense(max_span_end, activation='softmax')(biLSTM)\n",
    "\n",
    "model = Model(inputs=[context_input, ques_input], outputs=[softmax_1, softmax_2])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model_history = model.fit([context_array[:slce], question_array[:slce]], [begin_span[:slce], end_span[:slce]], verbose=2, batch_size=batch, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " - 362s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0110 - dense_6_acc: 0.0090\n",
      "Epoch 2/25\n",
      " - 326s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 3/25\n",
      " - 328s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 4/25\n",
      " - 328s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 5/25\n",
      " - 326s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 6/25\n",
      " - 322s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 7/25\n",
      " - 322s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 8/25\n",
      " - 321s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 9/25\n",
      " - 322s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 10/25\n",
      " - 321s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 11/25\n",
      " - 322s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 12/25\n",
      " - 322s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 13/25\n",
      " - 322s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 14/25\n",
      " - 323s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 15/25\n",
      " - 319s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 16/25\n",
      " - 320s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 17/25\n",
      " - 321s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 18/25\n",
      " - 322s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 19/25\n",
      " - 322s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 20/25\n",
      " - 320s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 21/25\n",
      " - 321s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 22/25\n",
      " - 322s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 23/25\n",
      " - 322s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 24/25\n",
      " - 322s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 25/25\n",
      " - 321s - loss: nan - dense_5_loss: nan - dense_6_loss: nan - dense_5_acc: 0.0120 - dense_6_acc: 0.0000e+00\n",
      "Epoch 1/100\n",
      " - 322s - loss: 7.1382 - dense_5_loss: 3.5608 - dense_6_loss: 3.5774 - dense_5_acc: 0.0930 - dense_6_acc: 0.0860\n",
      "Epoch 2/100\n",
      " - 319s - loss: 7.0630 - dense_5_loss: 3.5207 - dense_6_loss: 3.5422 - dense_5_acc: 0.0990 - dense_6_acc: 0.0910\n",
      "Epoch 3/100\n",
      " - 319s - loss: 7.0613 - dense_5_loss: 3.5205 - dense_6_loss: 3.5408 - dense_5_acc: 0.1020 - dense_6_acc: 0.0870\n",
      "Epoch 4/100\n",
      " - 318s - loss: 7.0386 - dense_5_loss: 3.5093 - dense_6_loss: 3.5293 - dense_5_acc: 0.1060 - dense_6_acc: 0.0890\n",
      "Epoch 5/100\n",
      " - 319s - loss: 7.0393 - dense_5_loss: 3.5071 - dense_6_loss: 3.5322 - dense_5_acc: 0.0990 - dense_6_acc: 0.0850\n",
      "Epoch 6/100\n",
      " - 319s - loss: 7.0234 - dense_5_loss: 3.5038 - dense_6_loss: 3.5196 - dense_5_acc: 0.0960 - dense_6_acc: 0.0950\n",
      "Epoch 7/100\n",
      " - 318s - loss: 7.0260 - dense_5_loss: 3.4997 - dense_6_loss: 3.5263 - dense_5_acc: 0.1000 - dense_6_acc: 0.0870\n",
      "Epoch 8/100\n",
      " - 316s - loss: 7.0110 - dense_5_loss: 3.4968 - dense_6_loss: 3.5142 - dense_5_acc: 0.1020 - dense_6_acc: 0.0890\n",
      "Epoch 9/100\n",
      " - 319s - loss: 7.0222 - dense_5_loss: 3.5033 - dense_6_loss: 3.5189 - dense_5_acc: 0.0990 - dense_6_acc: 0.0840\n",
      "Epoch 10/100\n",
      " - 320s - loss: 7.0394 - dense_5_loss: 3.5083 - dense_6_loss: 3.5311 - dense_5_acc: 0.1020 - dense_6_acc: 0.0850\n",
      "Epoch 11/100\n",
      " - 319s - loss: 7.0153 - dense_5_loss: 3.5000 - dense_6_loss: 3.5153 - dense_5_acc: 0.0970 - dense_6_acc: 0.0910\n",
      "Epoch 12/100\n",
      " - 318s - loss: 7.0055 - dense_5_loss: 3.4891 - dense_6_loss: 3.5163 - dense_5_acc: 0.1030 - dense_6_acc: 0.0860\n",
      "Epoch 13/100\n",
      " - 318s - loss: 7.0159 - dense_5_loss: 3.4959 - dense_6_loss: 3.5200 - dense_5_acc: 0.0970 - dense_6_acc: 0.0840\n",
      "Epoch 14/100\n",
      " - 318s - loss: 7.0380 - dense_5_loss: 3.5083 - dense_6_loss: 3.5297 - dense_5_acc: 0.0960 - dense_6_acc: 0.0880\n",
      "Epoch 15/100\n",
      " - 317s - loss: 7.0094 - dense_5_loss: 3.4926 - dense_6_loss: 3.5168 - dense_5_acc: 0.1010 - dense_6_acc: 0.0880\n",
      "Epoch 16/100\n",
      " - 318s - loss: 7.0061 - dense_5_loss: 3.4929 - dense_6_loss: 3.5132 - dense_5_acc: 0.0990 - dense_6_acc: 0.0850\n",
      "Epoch 17/100\n",
      " - 318s - loss: 7.0167 - dense_5_loss: 3.4974 - dense_6_loss: 3.5193 - dense_5_acc: 0.0980 - dense_6_acc: 0.0860\n",
      "Epoch 18/100\n",
      " - 319s - loss: 7.0141 - dense_5_loss: 3.4948 - dense_6_loss: 3.5193 - dense_5_acc: 0.1020 - dense_6_acc: 0.0840\n",
      "Epoch 19/100\n",
      " - 320s - loss: 7.0119 - dense_5_loss: 3.4927 - dense_6_loss: 3.5192 - dense_5_acc: 0.1010 - dense_6_acc: 0.0850\n",
      "Epoch 20/100\n",
      " - 319s - loss: 7.0146 - dense_5_loss: 3.4952 - dense_6_loss: 3.5194 - dense_5_acc: 0.0970 - dense_6_acc: 0.0870\n",
      "Epoch 21/100\n",
      " - 319s - loss: 7.0042 - dense_5_loss: 3.4914 - dense_6_loss: 3.5127 - dense_5_acc: 0.0950 - dense_6_acc: 0.0820\n",
      "Epoch 22/100\n",
      " - 320s - loss: 6.9957 - dense_5_loss: 3.4863 - dense_6_loss: 3.5094 - dense_5_acc: 0.1000 - dense_6_acc: 0.0840\n",
      "Epoch 23/100\n",
      " - 319s - loss: 7.0017 - dense_5_loss: 3.4908 - dense_6_loss: 3.5109 - dense_5_acc: 0.0980 - dense_6_acc: 0.0840\n",
      "Epoch 24/100\n",
      " - 319s - loss: 7.0038 - dense_5_loss: 3.4899 - dense_6_loss: 3.5139 - dense_5_acc: 0.0970 - dense_6_acc: 0.0850\n",
      "Epoch 25/100\n",
      " - 319s - loss: 6.9977 - dense_5_loss: 3.4874 - dense_6_loss: 3.5103 - dense_5_acc: 0.1000 - dense_6_acc: 0.0870\n",
      "Epoch 26/100\n",
      " - 319s - loss: 7.0116 - dense_5_loss: 3.4960 - dense_6_loss: 3.5157 - dense_5_acc: 0.0990 - dense_6_acc: 0.0830\n",
      "Epoch 27/100\n",
      " - 318s - loss: 7.0050 - dense_5_loss: 3.4898 - dense_6_loss: 3.5152 - dense_5_acc: 0.0950 - dense_6_acc: 0.0770\n",
      "Epoch 28/100\n",
      " - 319s - loss: 6.9932 - dense_5_loss: 3.4874 - dense_6_loss: 3.5058 - dense_5_acc: 0.0990 - dense_6_acc: 0.0880\n",
      "Epoch 29/100\n",
      " - 319s - loss: 7.0113 - dense_5_loss: 3.4912 - dense_6_loss: 3.5201 - dense_5_acc: 0.0940 - dense_6_acc: 0.0910\n",
      "Epoch 30/100\n",
      " - 318s - loss: 6.9977 - dense_5_loss: 3.4871 - dense_6_loss: 3.5106 - dense_5_acc: 0.0990 - dense_6_acc: 0.0840\n",
      "Epoch 31/100\n",
      " - 317s - loss: 6.9937 - dense_5_loss: 3.4853 - dense_6_loss: 3.5084 - dense_5_acc: 0.0960 - dense_6_acc: 0.0810\n",
      "Epoch 32/100\n",
      " - 318s - loss: 7.0089 - dense_5_loss: 3.4945 - dense_6_loss: 3.5144 - dense_5_acc: 0.0940 - dense_6_acc: 0.0890\n",
      "Epoch 33/100\n",
      " - 319s - loss: 6.9996 - dense_5_loss: 3.4866 - dense_6_loss: 3.5130 - dense_5_acc: 0.0950 - dense_6_acc: 0.0870\n",
      "Epoch 34/100\n",
      " - 319s - loss: 6.9925 - dense_5_loss: 3.4838 - dense_6_loss: 3.5087 - dense_5_acc: 0.1020 - dense_6_acc: 0.0860\n",
      "Epoch 35/100\n",
      " - 319s - loss: 7.0068 - dense_5_loss: 3.4898 - dense_6_loss: 3.5170 - dense_5_acc: 0.0970 - dense_6_acc: 0.0820\n",
      "Epoch 36/100\n",
      " - 319s - loss: 6.9963 - dense_5_loss: 3.4877 - dense_6_loss: 3.5086 - dense_5_acc: 0.1010 - dense_6_acc: 0.0880\n",
      "Epoch 37/100\n",
      " - 319s - loss: 6.9963 - dense_5_loss: 3.4858 - dense_6_loss: 3.5105 - dense_5_acc: 0.0970 - dense_6_acc: 0.0800\n",
      "Epoch 38/100\n",
      " - 318s - loss: 6.9987 - dense_5_loss: 3.4881 - dense_6_loss: 3.5106 - dense_5_acc: 0.0930 - dense_6_acc: 0.0800\n",
      "Epoch 39/100\n",
      " - 319s - loss: 6.9933 - dense_5_loss: 3.4861 - dense_6_loss: 3.5073 - dense_5_acc: 0.0920 - dense_6_acc: 0.0830\n",
      "Epoch 40/100\n",
      " - 319s - loss: 6.9942 - dense_5_loss: 3.4859 - dense_6_loss: 3.5083 - dense_5_acc: 0.0950 - dense_6_acc: 0.0790\n",
      "Epoch 41/100\n",
      " - 319s - loss: 6.9945 - dense_5_loss: 3.4867 - dense_6_loss: 3.5078 - dense_5_acc: 0.0980 - dense_6_acc: 0.0840\n",
      "Epoch 42/100\n",
      " - 320s - loss: 6.9911 - dense_5_loss: 3.4867 - dense_6_loss: 3.5043 - dense_5_acc: 0.0880 - dense_6_acc: 0.0820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100\n",
      " - 320s - loss: 7.0027 - dense_5_loss: 3.4892 - dense_6_loss: 3.5136 - dense_5_acc: 0.0990 - dense_6_acc: 0.0810\n",
      "Epoch 44/100\n",
      " - 319s - loss: 6.9901 - dense_5_loss: 3.4837 - dense_6_loss: 3.5064 - dense_5_acc: 0.1010 - dense_6_acc: 0.0750\n",
      "Epoch 45/100\n",
      " - 319s - loss: 7.0011 - dense_5_loss: 3.4858 - dense_6_loss: 3.5152 - dense_5_acc: 0.0940 - dense_6_acc: 0.0750\n",
      "Epoch 46/100\n",
      " - 319s - loss: 6.9894 - dense_5_loss: 3.4857 - dense_6_loss: 3.5037 - dense_5_acc: 0.0990 - dense_6_acc: 0.0800\n",
      "Epoch 47/100\n",
      " - 318s - loss: 6.9887 - dense_5_loss: 3.4823 - dense_6_loss: 3.5065 - dense_5_acc: 0.0990 - dense_6_acc: 0.0790\n",
      "Epoch 48/100\n",
      " - 318s - loss: 6.9970 - dense_5_loss: 3.4866 - dense_6_loss: 3.5104 - dense_5_acc: 0.1010 - dense_6_acc: 0.0830\n",
      "Epoch 49/100\n",
      " - 319s - loss: 6.9824 - dense_5_loss: 3.4802 - dense_6_loss: 3.5022 - dense_5_acc: 0.1020 - dense_6_acc: 0.0810\n",
      "Epoch 50/100\n",
      " - 320s - loss: 6.9852 - dense_5_loss: 3.4821 - dense_6_loss: 3.5031 - dense_5_acc: 0.1010 - dense_6_acc: 0.0860\n",
      "Epoch 51/100\n",
      " - 320s - loss: 6.9885 - dense_5_loss: 3.4816 - dense_6_loss: 3.5069 - dense_5_acc: 0.0960 - dense_6_acc: 0.0790\n",
      "Epoch 52/100\n",
      " - 320s - loss: 6.9978 - dense_5_loss: 3.4842 - dense_6_loss: 3.5135 - dense_5_acc: 0.0930 - dense_6_acc: 0.0820\n",
      "Epoch 53/100\n",
      " - 5576s - loss: 6.9990 - dense_5_loss: 3.4839 - dense_6_loss: 3.5151 - dense_5_acc: 0.1000 - dense_6_acc: 0.0760\n",
      "Epoch 54/100\n",
      " - 331s - loss: 6.9812 - dense_5_loss: 3.4776 - dense_6_loss: 3.5036 - dense_5_acc: 0.0980 - dense_6_acc: 0.0840\n",
      "Epoch 55/100\n",
      " - 320s - loss: 6.9866 - dense_5_loss: 3.4792 - dense_6_loss: 3.5074 - dense_5_acc: 0.0950 - dense_6_acc: 0.0810\n",
      "Epoch 56/100\n",
      " - 320s - loss: 6.9887 - dense_5_loss: 3.4833 - dense_6_loss: 3.5054 - dense_5_acc: 0.1000 - dense_6_acc: 0.0900\n",
      "Epoch 57/100\n",
      " - 323s - loss: 6.9840 - dense_5_loss: 3.4797 - dense_6_loss: 3.5043 - dense_5_acc: 0.1030 - dense_6_acc: 0.0850\n",
      "Epoch 58/100\n",
      " - 322s - loss: 6.9804 - dense_5_loss: 3.4764 - dense_6_loss: 3.5040 - dense_5_acc: 0.0960 - dense_6_acc: 0.0820\n",
      "Epoch 59/100\n",
      " - 324s - loss: 6.9937 - dense_5_loss: 3.4832 - dense_6_loss: 3.5104 - dense_5_acc: 0.0960 - dense_6_acc: 0.0800\n",
      "Epoch 60/100\n",
      " - 328s - loss: 6.9893 - dense_5_loss: 3.4825 - dense_6_loss: 3.5068 - dense_5_acc: 0.0910 - dense_6_acc: 0.0870\n",
      "Epoch 61/100\n",
      " - 324s - loss: 6.9767 - dense_5_loss: 3.4781 - dense_6_loss: 3.4985 - dense_5_acc: 0.1040 - dense_6_acc: 0.0880\n",
      "Epoch 62/100\n",
      " - 323s - loss: 6.9902 - dense_5_loss: 3.4818 - dense_6_loss: 3.5084 - dense_5_acc: 0.0970 - dense_6_acc: 0.0790\n",
      "Epoch 63/100\n",
      " - 323s - loss: 6.9823 - dense_5_loss: 3.4811 - dense_6_loss: 3.5012 - dense_5_acc: 0.0930 - dense_6_acc: 0.0800\n",
      "Epoch 64/100\n",
      " - 326s - loss: 6.9837 - dense_5_loss: 3.4800 - dense_6_loss: 3.5037 - dense_5_acc: 0.0990 - dense_6_acc: 0.0840\n",
      "Epoch 65/100\n",
      " - 322s - loss: 6.9937 - dense_5_loss: 3.4900 - dense_6_loss: 3.5036 - dense_5_acc: 0.0950 - dense_6_acc: 0.0800\n",
      "Epoch 66/100\n",
      " - 322s - loss: 6.9757 - dense_5_loss: 3.4730 - dense_6_loss: 3.5027 - dense_5_acc: 0.0960 - dense_6_acc: 0.0820\n",
      "Epoch 67/100\n",
      " - 322s - loss: 6.9765 - dense_5_loss: 3.4778 - dense_6_loss: 3.4987 - dense_5_acc: 0.1020 - dense_6_acc: 0.0820\n",
      "Epoch 68/100\n",
      " - 323s - loss: 6.9869 - dense_5_loss: 3.4818 - dense_6_loss: 3.5051 - dense_5_acc: 0.1010 - dense_6_acc: 0.0840\n",
      "Epoch 69/100\n",
      " - 323s - loss: 6.9797 - dense_5_loss: 3.4764 - dense_6_loss: 3.5033 - dense_5_acc: 0.0990 - dense_6_acc: 0.0890\n",
      "Epoch 70/100\n",
      " - 323s - loss: 6.9743 - dense_5_loss: 3.4775 - dense_6_loss: 3.4968 - dense_5_acc: 0.1050 - dense_6_acc: 0.0800\n",
      "Epoch 71/100\n",
      " - 323s - loss: 6.9803 - dense_5_loss: 3.4783 - dense_6_loss: 3.5021 - dense_5_acc: 0.0920 - dense_6_acc: 0.0800\n",
      "Epoch 72/100\n",
      " - 323s - loss: 6.9876 - dense_5_loss: 3.4792 - dense_6_loss: 3.5085 - dense_5_acc: 0.0920 - dense_6_acc: 0.0790\n",
      "Epoch 73/100\n",
      " - 325s - loss: 6.9813 - dense_5_loss: 3.4814 - dense_6_loss: 3.4999 - dense_5_acc: 0.0960 - dense_6_acc: 0.0810\n",
      "Epoch 74/100\n",
      " - 323s - loss: 6.9846 - dense_5_loss: 3.4814 - dense_6_loss: 3.5032 - dense_5_acc: 0.0960 - dense_6_acc: 0.0840\n",
      "Epoch 75/100\n",
      " - 322s - loss: 6.9839 - dense_5_loss: 3.4806 - dense_6_loss: 3.5034 - dense_5_acc: 0.0970 - dense_6_acc: 0.0800\n",
      "Epoch 76/100\n",
      " - 323s - loss: 6.9777 - dense_5_loss: 3.4769 - dense_6_loss: 3.5008 - dense_5_acc: 0.0980 - dense_6_acc: 0.0860\n",
      "Epoch 77/100\n",
      " - 324s - loss: 6.9784 - dense_5_loss: 3.4771 - dense_6_loss: 3.5013 - dense_5_acc: 0.0930 - dense_6_acc: 0.0850\n",
      "Epoch 78/100\n",
      " - 322s - loss: 6.9781 - dense_5_loss: 3.4772 - dense_6_loss: 3.5009 - dense_5_acc: 0.0950 - dense_6_acc: 0.0820\n",
      "Epoch 79/100\n",
      " - 323s - loss: 6.9750 - dense_5_loss: 3.4777 - dense_6_loss: 3.4973 - dense_5_acc: 0.0930 - dense_6_acc: 0.0780\n",
      "Epoch 80/100\n",
      " - 322s - loss: 6.9801 - dense_5_loss: 3.4774 - dense_6_loss: 3.5026 - dense_5_acc: 0.0960 - dense_6_acc: 0.0840\n",
      "Epoch 81/100\n",
      " - 325s - loss: 6.9827 - dense_5_loss: 3.4802 - dense_6_loss: 3.5025 - dense_5_acc: 0.0970 - dense_6_acc: 0.0770\n",
      "Epoch 82/100\n",
      " - 323s - loss: 6.9793 - dense_5_loss: 3.4810 - dense_6_loss: 3.4983 - dense_5_acc: 0.1000 - dense_6_acc: 0.0940\n",
      "Epoch 83/100\n",
      " - 324s - loss: 6.9793 - dense_5_loss: 3.4782 - dense_6_loss: 3.5011 - dense_5_acc: 0.0960 - dense_6_acc: 0.0840\n",
      "Epoch 84/100\n",
      " - 324s - loss: 6.9807 - dense_5_loss: 3.4822 - dense_6_loss: 3.4984 - dense_5_acc: 0.0950 - dense_6_acc: 0.0920\n",
      "Epoch 85/100\n",
      " - 323s - loss: 6.9773 - dense_5_loss: 3.4764 - dense_6_loss: 3.5009 - dense_5_acc: 0.1000 - dense_6_acc: 0.0780\n",
      "Epoch 86/100\n",
      " - 325s - loss: 6.9889 - dense_5_loss: 3.4842 - dense_6_loss: 3.5047 - dense_5_acc: 0.0870 - dense_6_acc: 0.0850\n",
      "Epoch 87/100\n",
      " - 323s - loss: 6.9758 - dense_5_loss: 3.4764 - dense_6_loss: 3.4994 - dense_5_acc: 0.0910 - dense_6_acc: 0.0870\n",
      "Epoch 88/100\n",
      " - 323s - loss: 6.9785 - dense_5_loss: 3.4783 - dense_6_loss: 3.5002 - dense_5_acc: 0.0900 - dense_6_acc: 0.0750\n",
      "Epoch 89/100\n",
      " - 323s - loss: 6.9860 - dense_5_loss: 3.4809 - dense_6_loss: 3.5051 - dense_5_acc: 0.0900 - dense_6_acc: 0.0810\n",
      "Epoch 90/100\n",
      " - 323s - loss: 6.9789 - dense_5_loss: 3.4773 - dense_6_loss: 3.5016 - dense_5_acc: 0.0940 - dense_6_acc: 0.0840\n",
      "Epoch 91/100\n",
      " - 323s - loss: 6.9755 - dense_5_loss: 3.4776 - dense_6_loss: 3.4978 - dense_5_acc: 0.0900 - dense_6_acc: 0.0800\n",
      "Epoch 92/100\n",
      " - 340s - loss: 6.9724 - dense_5_loss: 3.4732 - dense_6_loss: 3.4992 - dense_5_acc: 0.0970 - dense_6_acc: 0.0820\n",
      "Epoch 93/100\n",
      " - 327s - loss: 6.9732 - dense_5_loss: 3.4748 - dense_6_loss: 3.4984 - dense_5_acc: 0.0920 - dense_6_acc: 0.0820\n",
      "Epoch 94/100\n",
      " - 325s - loss: 6.9793 - dense_5_loss: 3.4767 - dense_6_loss: 3.5026 - dense_5_acc: 0.0960 - dense_6_acc: 0.0840\n",
      "Epoch 95/100\n",
      " - 323s - loss: 6.9757 - dense_5_loss: 3.4755 - dense_6_loss: 3.5002 - dense_5_acc: 0.0940 - dense_6_acc: 0.0760\n",
      "Epoch 96/100\n",
      " - 322s - loss: 6.9712 - dense_5_loss: 3.4753 - dense_6_loss: 3.4959 - dense_5_acc: 0.0860 - dense_6_acc: 0.0840\n",
      "Epoch 97/100\n",
      " - 322s - loss: 6.9687 - dense_5_loss: 3.4731 - dense_6_loss: 3.4956 - dense_5_acc: 0.0970 - dense_6_acc: 0.0790\n",
      "Epoch 98/100\n",
      " - 323s - loss: 6.9681 - dense_5_loss: 3.4730 - dense_6_loss: 3.4951 - dense_5_acc: 0.0980 - dense_6_acc: 0.0780\n",
      "Epoch 99/100\n",
      " - 323s - loss: 6.9712 - dense_5_loss: 3.4733 - dense_6_loss: 3.4978 - dense_5_acc: 0.0920 - dense_6_acc: 0.0780\n",
      "Epoch 100/100\n",
      " - 322s - loss: 6.9738 - dense_5_loss: 3.4760 - dense_6_loss: 3.4979 - dense_5_acc: 0.0900 - dense_6_acc: 0.0800\n"
     ]
    }
   ],
   "source": [
    "model.fit([context_array[stindex:endindex], question_array[stindex:endindex]],\n",
    "                [begin_span[stindex:endindex], end_span[stindex:endindex]], verbose=2,\n",
    "                 batch_size=batch, epochs=25)\n",
    "model.save_weights('./dropout/adam01_25epochs')\n",
    "model.load_weights('./adam001_120epochs')\n",
    "stindex=1000\n",
    "endindex=2000\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.summary()\n",
    "history = model.fit([context_array[stindex:endindex], question_array[stindex:endindex]],\n",
    "                [begin_span[stindex:endindex], end_span[stindex:endindex]], verbose=2,\n",
    "                 batch_size=batch, epochs=100)\n",
    "model.save_weights('./adam0001_220epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 21140s - loss: 27.2224 - dense_1_loss: 13.5343 - dense_2_loss: 13.6881 - dense_1_acc: 0.0060 - dense_2_acc: 0.0000e+00\n",
      "Epoch 2/50\n"
     ]
    }
   ],
   "source": [
    "stindex=0\n",
    "endindex=1000\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.load_weights('./model70_epochs0')\n",
    "#model.summary()\n",
    "history = model.fit([context_array[stindex:endindex], question_array[stindex:endindex]],\n",
    "                [begin_span[stindex:endindex], end_span[stindex:endindex]], verbose=2,\n",
    "                 batch_size=batch, epochs=50)\n",
    "model.save_weights('./Weights_adam001_170epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
